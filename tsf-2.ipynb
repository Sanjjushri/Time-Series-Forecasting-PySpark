{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d52b3113-efd2-48c4-9043-7687131c72cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fc26d91-a33d-4e9c-83fa-453666fc91fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "StructField(\"DATE\", DateType()),\n",
    "StructField(\"COUNTRY\", StringType()),\n",
    "StructField(\"CITY\", StringType()),\n",
    "StructField(\"VALUE\", DoubleType())])\n",
    "\n",
    "spark = SparkSession.builder.appName('TSF-pollution').getOrCreate()\n",
    "\n",
    "df = spark.read.csv(\"/Users/sanjju/projects/datasets/air_quality_index.csv\", header = 'true', schema=schema)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c80090e-f3da-45b8-bede-a6248175fe19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# @udf(VectorUDT())\n",
    "def toSparseVector(index, values):\n",
    "    day_list_index, qty_list_values = zip(*sorted(zip(index, values)))\n",
    "    #367 for bisextile year (1 to 366 +1)\n",
    "    return Vectors.sparse(367, day_list_index, qty_list_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22ca35f3-c6a5-4383-b9bc-05031cf1ee97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import HiveContext, Window, DataFrameWriter, Row\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.regression import GeneralizedLinearRegression\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "import sys\n",
    "from operator import add\n",
    "from functools import reduce, wraps\n",
    "import logging, time\n",
    "from functools import wraps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82f64a49-ae23-489c-a29b-0bd068d4282a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.regression import *\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "import numpy as np\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import PCA\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, Imputer\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.regression import *\n",
    "\n",
    "\n",
    "# from features_utils import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5c2eeab-abb1-4442-98e5-54e3cd9c5126",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "StructField(\"DATE\", DateType()),\n",
    "StructField(\"COUNTRY\", StringType()),\n",
    "StructField(\"CITY\", StringType()),\n",
    "StructField(\"VALUE\", DoubleType())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b571d826-a407-48d3-bd08-a68958ab18ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('TSF').getOrCreate()\n",
    "\n",
    "df = spark.read.csv(\"dataset/air_quality_index.csv\", header = 'true', schema=schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2cd6fccd-30de-4185-83c6-428029a3f616",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Column is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m df \u001b[38;5;241m=\u001b[39m (df\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;241m.\u001b[39mwithColumn(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myearday\u001b[39m\u001b[38;5;124m'\u001b[39m, F\u001b[38;5;241m.\u001b[39mdayofyear(F\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDATE\u001b[39m\u001b[38;5;124m\"\u001b[39m)))\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;241m.\u001b[39mwithColumn(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m, F\u001b[38;5;241m.\u001b[39myear(F\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDATE\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n\u001b[1;32m      4\u001b[0m     )\n\u001b[1;32m      6\u001b[0m self_join \u001b[38;5;241m=\u001b[39m (df\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCOUNTRY\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;241m.\u001b[39magg(\n\u001b[1;32m      9\u001b[0m         F\u001b[38;5;241m.\u001b[39mcollect_list(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCOUNTRY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqties\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     10\u001b[0m          F\u001b[38;5;241m.\u001b[39mcollect_list(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myearday\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdays\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m          )\n\u001b[0;32m---> 12\u001b[0m     \u001b[38;5;241m.\u001b[39mwithColumn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqties_vectorized\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mtoSparseVector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdays\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mqties\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;241m.\u001b[39mwithColumn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myear_join\u001b[39m\u001b[38;5;124m\"\u001b[39m, F\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     14\u001b[0m      \u001b[38;5;241m.\u001b[39mselect(\n\u001b[1;32m     15\u001b[0m       F\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSID_STORE\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mp_id_store\u001b[39m\u001b[38;5;124m\"\u001b[39m), F\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myear2\u001b[39m\u001b[38;5;124m\"\u001b[39m), F\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqties_vectorized\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqties_vectorized\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     16\u001b[0m        F\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdays\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdayss\u001b[39m\u001b[38;5;124m\"\u001b[39m),  F\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqties\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqties\u001b[39m\u001b[38;5;124m\"\u001b[39m),  F\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myear_join\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myear_join\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m         )\n\u001b[1;32m     18\u001b[0m      )\n\u001b[1;32m     21\u001b[0m df\u001b[38;5;241m=\u001b[39m (df\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;241m.\u001b[39mjoin(self_join\n\u001b[1;32m     23\u001b[0m         , ([self_join\u001b[38;5;241m.\u001b[39mp_id_store \u001b[38;5;241m==\u001b[39m df\u001b[38;5;241m.\u001b[39mSID_STORE, self_join\u001b[38;5;241m.\u001b[39myear_join \u001b[38;5;241m==\u001b[39m  df\u001b[38;5;241m.\u001b[39myear]),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[38;5;241m.\u001b[39mwithColumn(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mqty_reference\u001b[39m\u001b[38;5;124m'\u001b[39m, F\u001b[38;5;241m.\u001b[39mwhen(F\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqty_reference\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39misNull(), F\u001b[38;5;241m.\u001b[39mlit(\u001b[38;5;241m0\u001b[39m))\u001b[38;5;241m.\u001b[39motherwise(F\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqty_reference\u001b[39m\u001b[38;5;124m\"\u001b[39m)))\n\u001b[1;32m     29\u001b[0m     )\n",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36mtoSparseVector\u001b[0;34m(index, values)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtoSparseVector\u001b[39m(index, values):\n\u001b[0;32m----> 3\u001b[0m     day_list_index, qty_list_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m#367 for bisextile year (1 to 366 +1)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Vectors\u001b[38;5;241m.\u001b[39msparse(\u001b[38;5;241m367\u001b[39m, day_list_index, qty_list_values)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/ml38/lib/python3.8/site-packages/pyspark/sql/column.py:560\u001b[0m, in \u001b[0;36mColumn.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 560\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumn is not iterable\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Column is not iterable"
     ]
    }
   ],
   "source": [
    "df = (df\n",
    "    .withColumn('yearday', F.dayofyear(F.col(\"DATE\")))\n",
    "    .withColumn('year', F.year(F.col('DATE')))\n",
    "    )\n",
    "\n",
    "self_join = (df\n",
    "    .groupby(\"COUNTRY\", \"year\")\n",
    "    .agg(\n",
    "        F.collect_list(\"COUNTRY\").alias(\"qties\"),\n",
    "         F.collect_list(\"yearday\").alias(\"days\")\n",
    "         )\n",
    "    .withColumn(\"qties_vectorized\", toSparseVector(F.col(\"days\"), F.col(\"qties\")))\n",
    "    .withColumn(\"year_join\", F.col(\"year\") + 1)\n",
    "     .select(\n",
    "      F.col(\"SID_STORE\").alias(\"p_id_store\"), F.col(\"year\").alias(\"year2\"), F.col(\"qties_vectorized\").alias(\"qties_vectorized\"),\n",
    "       F.col(\"days\").alias(\"dayss\"),  F.col(\"qties\").alias(\"qties\"),  F.col(\"year_join\").alias(\"year_join\")\n",
    "        )\n",
    "     )\n",
    "\n",
    "\n",
    "df= (df\n",
    "    .join(self_join\n",
    "        , ([self_join.p_id_store == df.SID_STORE, self_join.year_join ==  df.year]),\n",
    "        how = \"left\"\n",
    "        )\n",
    "        .withColumn(\"qty_reference\", getReference(F.col(\"yearday\"), F.col(\"qties_vectorized\")))\n",
    "        .withColumn('qty_reference', F.col(\"qty_reference\").cast(DoubleType()))\n",
    "        .withColumn('qty_reference', F.when(F.col(\"qty_reference\").isNull(), F.lit(0)).otherwise(F.col(\"qty_reference\")))\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6803c242-4d54-400c-adac-a42418410f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dex = DayExtractor(inputCol='DATE')\n",
    "mex = MonthExtractor(inputCol='DATE')\n",
    "yex = YearExtractor(inputCol='DATE')\n",
    "wdex = WeekDayExtractor(inputCol='DATE')\n",
    "wex = WeekendExtractor()\n",
    "vex = VivaldiExtractor(inputCol = \"month\")\n",
    "mqex = MonthQuarterExtractor(inputCol = \"day\")\n",
    "mbex = MonthBeginExtractor()\n",
    "meex = MonthEndExtractor()\n",
    "yqex = YearQuarterExtractor()\n",
    "ydex = YearDayExtractor(inputCol='DATE')\n",
    "\n",
    "numeric_col= [\"VALUE\"]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
